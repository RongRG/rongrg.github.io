<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>architecture on Rong&#39;s Homepage</title>
    <link>https://rongrg.github.io/tags/architecture/</link>
    <description>Recent content in architecture on Rong&#39;s Homepage</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 10 Feb 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://rongrg.github.io/tags/architecture/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Understanding LSTM Networks: An Overview of Layers, Cells, Neurons, and Units</title>
      <link>https://rongrg.github.io/posts/2023-02-10-lstm/</link>
      <pubDate>Fri, 10 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>https://rongrg.github.io/posts/2023-02-10-lstm/</guid>
      <description>LSTM is a type of recurrent neural network (RNN) that is widely used in natural language processing, speech recognition, and other applications where sequential data is important. LSTMs are particularly effective at capturing long-term dependencies in sequences of data, which can be challenging for other types of neural networks.
Navigating the jargon associated with the components of LSTM networks can be daunting, even for those familiar with neural networks. Terms like &amp;ldquo;cell,&amp;rdquo; &amp;ldquo;layer,&amp;rdquo; &amp;ldquo;unit,&amp;rdquo; and &amp;ldquo;neuron&amp;rdquo; are often thrown around without a clear explanation of their meaning and purpose.</description>
    </item>
    
  </channel>
</rss>
